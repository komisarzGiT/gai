{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=img/MScAI_brand.png width=70%></center>\n",
    "\n",
    "# Scikit-Learn: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "When approaching an ML problem we often train multiple models. There are at least three possibilities:\n",
    "\n",
    "* Different models *per se*, e.g. Logistic Regression versus SVM\n",
    "* Tuning hyperparameter values (aka **model selection**)\n",
    "* Different features (**feature selection**)\n",
    "\n",
    "This notebook is mostly about hyperparameter tuning, plus a quick example of multiple models. We'll cover feature selection in the next. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's compare a `LinearRegression` with the `RandomForestRegressor` which is an ensemble of decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The **diabetes** dataset is a well-known \"toy\" dataset for testing out regression algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442, 10), (442,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_diabetes(return_X_y=True)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03807591  0.05068012  0.06169621  0.02187235 -0.0442235  -0.03482076\n",
      "  -0.04340085 -0.00259226  0.01990842 -0.01764613]\n",
      " [-0.00188202 -0.04464164 -0.05147406 -0.02632783 -0.00844872 -0.01916334\n",
      "   0.07441156 -0.03949338 -0.06832974 -0.09220405]\n",
      " [ 0.08529891  0.05068012  0.04445121 -0.00567061 -0.04559945 -0.03419447\n",
      "  -0.03235593 -0.00259226  0.00286377 -0.02593034]\n",
      " [-0.08906294 -0.04464164 -0.01159501 -0.03665645  0.01219057  0.02499059\n",
      "  -0.03603757  0.03430886  0.02269202 -0.00936191]\n",
      " [ 0.00538306 -0.04464164 -0.03638469  0.02187235  0.00393485  0.01559614\n",
      "   0.00814208 -0.00259226 -0.03199144 -0.04664087]]\n",
      "[151.  75. 141. 206. 135.]\n"
     ]
    }
   ],
   "source": [
    "print(X[:5])\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll make a train-test split. It's good practice to use a `random_state`, so that anyone else who runs our notebook will get exactly the same train-test split as us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, the point of this exercise: if we put several models into a list, then we can use a loop to fit and evaluate them all on a test set. This is good scientific practice: it ensures that all are trained and evaluated in exactly the same way.\n",
    "\n",
    "We can even do some hyperparameter tuning in this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LinearRegression(),\n",
    "    RandomForestRegressor(max_depth=3),\n",
    "    RandomForestRegressor(max_depth=10),\n",
    "    RandomForestRegressor(max_depth=20)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(): 0.36\n",
      "RandomForestRegressor(max_depth=3): 0.26\n",
      "RandomForestRegressor(max_depth=10): 0.24\n",
      "RandomForestRegressor(max_depth=20): 0.27\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"{repr(model)}: {model.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Remember that by default the `score` for regression is the coefficient of determination $R^2$, where higher is better. It looks like the linear regression is the best (so far) on this dataset! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's notice that this is a nice example of **duck typing**: we have objects of different types `LinearRegression` and `RandomForestRegressor`, but it's fine because they all have `fit`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We could go further, and try out a factorial design on multiple hyperparameters, again using the same train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 0.005036263471429714\n",
      "1 4 -0.030175303514740515\n",
      "1 8 -0.3839607726192866\n",
      "1 16 -0.38368773188740146\n",
      "1 None -0.17998930461000429\n",
      "10 2 0.18797936594620124\n",
      "10 4 0.2238222412656934\n",
      "10 8 0.21950958155874456\n",
      "10 16 0.16619076684681944\n",
      "10 None 0.20491942359335658\n",
      "100 2 0.26611441247806633\n",
      "100 4 0.27645787478626593\n",
      "100 8 0.2566173693599645\n",
      "100 16 0.2387430173417251\n",
      "100 None 0.24536849562685736\n"
     ]
    }
   ],
   "source": [
    "n_estimatorss = [1, 10, 100]\n",
    "max_depths = [2, 4, 8, 16, None] # NB None means \"no max\"\n",
    "for n_estimators, max_depth in (\n",
    "    itertools.product(n_estimatorss, max_depths)):\n",
    "    \n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=n_estimators, \n",
    "        max_depth=max_depth)\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(f\"{n_estimators} {max_depth} {rf.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hyperparameter Tuning with Cross-Validation\n",
    "\n",
    "Next we'll look at a better approach to hyperparameter turning, using **cross-validation**.\n",
    "\n",
    "Disadvantages of a single train-test split:\n",
    "\n",
    "* Vulnerable to a single random decision (e.g. many \"easy\" examples in the test set)\n",
    "* Some of the data doesn't contribute to training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Cross-validation solves these problems by splitting the data into $k$ *folds*, and then training $k$ times, each time on $1-1/k$ of the data, and validating on the remaining $1/k$:\n",
    "\n",
    "<center><img src=img/grid_search_cross_validation.png width=40%></centre>\n",
    "\n",
    "<font size=1>https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Scikit-Learn provides easy interfaces for cross-validation.\n",
    "\n",
    "Notice that we **instantiate** the RF, but **we** don't fit it. The `cross_val_score` function will call `fit` 5 times and return the 5 values from the unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47257668, 0.47663777, 0.46703285, 0.3990208 , 0.54202861])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "rf = RandomForestRegressor(n_estimators=50, \n",
    "                           max_depth=8)\n",
    "cross_val_score(rf, X_train, y_train, cv=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see a *big* difference in performance due to different folds. This is a warning not to blindly trust the result of any single train-test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "That's why it's better to use CV to help tune hyperparameters. We'll use a factorial design as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 0.3235351070408104\n",
      "1 4 0.23780398440987857\n",
      "1 8 0.08777054778276028\n",
      "1 16 -0.15436064785076192\n",
      "1 None 0.02897105400395337\n",
      "10 2 0.46863211679478545\n",
      "10 4 0.4655115657947097\n",
      "10 8 0.463712201839847\n",
      "10 16 0.43926584565145665\n",
      "10 None 0.4216133640818417\n",
      "100 2 0.4677339723301569\n",
      "100 4 0.4865973857891942\n",
      "100 8 0.48311321733985124\n",
      "100 16 0.4876417234486432\n",
      "100 None 0.48204196653204223\n"
     ]
    }
   ],
   "source": [
    "n_estimatorss = [1, 10, 100]\n",
    "max_depths = [2, 4, 8, 16, None] # NB None means \"no max\"\n",
    "for n_estimators, max_depth in (\n",
    "    itertools.product(n_estimatorss, max_depths)):\n",
    "    rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    mean_score = cross_val_score(rf, X_train, y_train, cv=5).mean()     \n",
    "    print(f\"{n_estimators} {max_depth} {mean_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Grid Search\n",
    "\n",
    "The factorial design is also known as a **grid search** in the context of machine learning and optimisation. We did the grid search manually, but let's never do that again: Scikit-Learn provides it for us. We provide a `dict` giving the parameter names and the values to be tried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={'max_depth': [2, 4, 8, 16, None],\n",
       "                         'n_estimators': [1, 10, 100]})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'n_estimators': [1, 10, 100],\n",
    "              'max_depth': [2, 4, 8, 16, None]}\n",
    "grid = GridSearchCV(RandomForestRegressor(), \n",
    "                    param_grid, cv=5) \n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Notice that we create a `GridSearchCV` object and call `fit` on that. Again, we don't call `fit` on the RF.\n",
    "\n",
    "After `fit`, we can find out the best parameter values and the `score` on test data with those parameters. Notice this is our unseen test data, not used during cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8, 'n_estimators': 100}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22934099677565734"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Some other utilities\n",
    "\n",
    "* If you want to report several `score` functions, such as $R^2$ and mean square error, you can pass `scoring` to some of the CV and Grid Search function.\n",
    "* There is also **leave-one-out** cross-validation which can sometimes be useful when you have little data.\n",
    "* There is **stratified CV**.\n",
    "* And lots more https://scikit-learn.org/stable/model_selection.html\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
