{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=img/MScAI_brand.png width=70%></center>\n",
    "\n",
    "# Scikit-Learn and OOP: Exercises and Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.5 (default, Sep  4 2020, 02:22:02) \\n[Clang 10.0.0 ]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import doctest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C:\n",
    "    def __init__(self, data=17):\n",
    "        self.data = data\n",
    "    def __repr__(self):\n",
    "        return f\"C({self.data})\"\n",
    "    def __lt__(self, other):\n",
    "        return self.data < other.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Run this code and explain the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'C' and 'C'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d54718fe0e52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: '<=' not supported between instances of 'C' and 'C'"
     ]
    }
   ],
   "source": [
    "C(17) <= C(18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Run this code and explain the result. **Hint**: the special `id` function in Python gets the **location** of the object in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C(17) == C(17) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Edit the definition of `C`, implementing `__eq__` and `__le__`, to fix the problems above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C:\n",
    "    \"\"\"\n",
    "    >>> C(17) <= C(18)\n",
    "    True\n",
    "    >>> C(17) == C(17)\n",
    "    True\n",
    "    \"\"\"\n",
    "    def __init__(self, data=17):\n",
    "        self.data = data\n",
    "    def __repr__(self):\n",
    "        return f\"C({self.data})\"\n",
    "    def __lt__(self, other):\n",
    "        return self.data < other.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in NoName\n",
      "Trying:\n",
      "    C(17) <= C(18)\n",
      "Expecting:\n",
      "    True\n",
      "**********************************************************************\n",
      "File \"__main__\", line ?, in NoName\n",
      "Failed example:\n",
      "    C(17) <= C(18)\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"/Users/jmmcd/opt/anaconda3/lib/python3.8/doctest.py\", line 1336, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest NoName[0]>\", line 1, in <module>\n",
      "        C(17) <= C(18)\n",
      "    TypeError: '<=' not supported between instances of 'C' and 'C'\n",
      "Trying:\n",
      "    C(17) == C(17)\n",
      "Expecting:\n",
      "    True\n",
      "**********************************************************************\n",
      "File \"__main__\", line ?, in NoName\n",
      "Failed example:\n",
      "    C(17) == C(17)\n",
      "Expected:\n",
      "    True\n",
      "Got:\n",
      "    False\n"
     ]
    }
   ],
   "source": [
    "doctest.run_docstring_examples(C(), globals(), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "This is a classic OOP exercise. Implement a class `Vehicle`, and then create sub-classes `Bicycle` and `Car` from it using `super`. A `Vehicle` has some number of wheels, and a colour, and a method `move`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vehicle:\n",
    "    \"\"\"\n",
    "    >>> v = Vehicle()\n",
    "    >>> v.move()\n",
    "    The vehicle is moving in an abstract kind of way\n",
    "    \"\"\"\n",
    "    pass # REPLACE WITH YOUR CODE - remember, \"pass\" is a \"do-nothing\" placeholder.\n",
    "    \n",
    "class Bicycle(Vehicle):\n",
    "    \"\"\"\n",
    "    >>> b = Bicycle(\"red\")\n",
    "    >>> b.move()\n",
    "    The red bicycle is pedalling\n",
    "    \"\"\"\n",
    "    pass\n",
    "    \n",
    "class Car(Vehicle):\n",
    "    \"\"\"\n",
    "    >>> c = Car(\"blue\")\n",
    "    >>> c.move()\n",
    "    The blue car is combusting petrol\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctest.run_docstring_examples(Vehicle, globals(), verbose=True)\n",
    "doctest.run_docstring_examples(Bicycle, globals(), verbose=True)\n",
    "doctest.run_docstring_examples(Car, globals(), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise: predict the mode\n",
    "\n",
    "In many machine learning scenarios it's good to create a simple **baseline** to compare a more sophisticated algorithm against. In classification, one simple example is to predict the **mode** -- the most common $y$ value in the training data, ignoring the $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def mode(y):\n",
    "    \"\"\"\n",
    "    Example: Counter(\"aaba\") returns (item, count) tuples ordered by count:\n",
    "    [('a', 3), ('b', 1)]\n",
    "    So the most common item is at [0][0]\n",
    "    \"\"\"\n",
    "    return Counter(y).most_common()[0][0]\n",
    "mode(['a', 'a', 'b', 'a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `ModePredictor` class using the above code. Inherit from Scikit-Learn `BaseEstimator` and `ClassifierMixin`. Compare its classification accuracy on the dataset below against another classifier, such as `RandomForestClassifier`. Remember, we should **inherit** classification accuracy, not implement it ourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/unbalanced.csv\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"X0\", \"X1\"]].values\n",
    "y = df[\"y\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModePredictor(BaseEstimator, ClassifierMixin):\n",
    "    pass ## REPLACE WITH YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run the code below we should see a table of results like this:\n",
    "\n",
    "```python\n",
    "ModePredictor(): 0.90\n",
    "RandomForestClassifier(): 0.90\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [ModePredictor(), RandomForestClassifier()]\n",
    "for clf in clfs:\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f\"{clf}: {clf.score(X_test, y_test):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
